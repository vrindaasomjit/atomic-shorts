# -*- coding: utf-8 -*-
"""StoryboardAgent_LangGraph_final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_i-IIpBywGSlZMJfIebA7CMCg6mdJPrA
"""

# --- Install dependencies (Colab) ---
!pip install --upgrade langchain-openai langchain-core langgraph pypdf

import os, re, json, base64
from pypdf import PdfReader
from google.colab import userdata  # if not in Colab, replace with your own API key

# --- API KEY ---
api_key = userdata.get('OPENAI_API_KEY')
os.environ["OPENAI_API_KEY"] = api_key

# --- LangChain / LangGraph imports ---
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langgraph.graph import StateGraph, END

# ======================================================
# 1. Helper: load files (PDFs and images)
# ======================================================
def load_files(file_paths):
    """
    Load files from local paths. Supports PDFs and images.
    Returns (file_contexts, image_refs).
    """
    file_contexts, image_refs = [], []

    for path in file_paths:
        if path.lower().endswith(".pdf"):
            reader = PdfReader(path)
            text = ""
            for page in reader.pages[:5]:  # limit to first 5 pages
                text += page.extract_text() or ""
            file_contexts.append(f"From uploaded material {path}:\n{text}")

        elif path.lower().endswith((".png", ".jpg", ".jpeg")):
            with open(path, "rb") as f:
                b64 = base64.b64encode(f.read()).decode("utf-8")
            image_refs.append({
                "type": "image",
                "source": {
                    "type": "base64",
                    "media_type": "image/png",
                    "data": b64
                }
            })

        else:
            file_contexts.append(f"{path}: (unsupported format)")

    return file_contexts, image_refs


# ======================================================
# 2. Storyboard prompt template
# ======================================================
storyboard_prompt = ChatPromptTemplate.from_messages([
    ("system", """
You are a storyboard generator specialized in **materials science and chemistry education**.
Your job is to create clear, accurate, and engaging storyboards for explainer videos.

Guidelines:
- Use correct terminology (e.g., crystal lattice, dielectric constant, polarization, phonons).
- Provide age-appropriate analogies when asked (e.g., explain atoms as Lego blocks for younger audiences).
- Correct misconceptions.
- If user uploads PDFs or images, integrate their content as authoritative references and cite them as “(from uploaded material)”.
- Always structure your reply as a numbered list of **scenes**, each with:
          1. Scene Title and Scene duration
          2. Visual Description (be descriptive- for example, include colors, shapes, flow, and animations to use)
          3. Narration (clear, concise, age-appropriate, scientifically accurate)
        - **Do NOT include people, faces, animals, or any visuals that cannot be rendered in Manim, ASE, RDKit, or simple 2D graphics.**
- The storyboard elements must be ultimately built by valid objects in **Manim Community**, so create the script accordingly.

For every reply, produce TWO sections:

1. Human-readable storyboard (Markdown).
2. Machine-readable storyboard (JSON), in this schema:

{{
  "prompt": "string", <-- include the original user prompt here
  "title": "string",
  "age_level": "string",
  "video_length": "string",
  "scenes": [
    {{
      "scene_id": number,
      "title": "string",
      "narration": "string",
      "visuals": [{{"description": "string"}}]
    }}
  ]
}}

Copy the user's input prompt exactly into the 'prompt' field.
The JSON block must be enclosed between lines:
===JSON START===
... JSON here ...
===JSON END===
Do not add any explanations outside these two sections.
"""),
    ("user", "{prompt}")
])

# ======================================================
# 3. Chain + reply splitter
# ======================================================
storyboard_llm = ChatOpenAI(model="gpt-4o-mini", temperature=0, api_key=api_key)
storyboard_chain = storyboard_prompt | storyboard_llm | StrOutputParser()

def split_reply(reply: str):
    m = re.search(r'===JSON START===\s*(\{.*\})\s*===JSON END===', reply, re.S)
    json_block = None
    if m:
        try:
            json_block = json.loads(m.group(1))
        except Exception as e:
            print("⚠️ JSON parsing error:", e)
    md_block = reply.split("===JSON START===")[0].strip()
    return md_block, json_block


# ======================================================
# 4. LangGraph node
# ======================================================
def storyboard_agent(state: dict):
    conversation = state.get("conversation", [])
    user_prompt = state["prompt"]

    # If files are passed, load and merge them
    file_contexts, image_refs = [], []
    if "files" in state and state["files"]:
        file_contexts, image_refs = load_files(state["files"])
        if file_contexts:
            user_prompt += f"""

=== Uploaded Material ===
{chr(10).join(file_contexts)}
=== End Uploaded Material ===
"""

    conversation.append({"role": "user", "content": user_prompt})

    # Run LLM chain
    conv_text = "\n".join([f"{m['role'].upper()}: {m['content']}" for m in conversation])
    reply = storyboard_chain.invoke({"prompt": conv_text})

    conversation.append({"role": "assistant", "content": reply})
    md_block, storyboard_json = split_reply(reply)

    state["reply"] = reply
    state["md_block"] = md_block
    state["storyboard"] = storyboard_json
    state["conversation"] = conversation
    state["image_refs"] = image_refs  # keep images around if needed
    return state


# ======================================================
# 5. LangGraph workflow
# ======================================================
workflow = StateGraph(dict)
workflow.add_node("Storyboard", storyboard_agent)
workflow.set_entry_point("Storyboard")
workflow.add_edge("Storyboard", END)
app = workflow.compile()